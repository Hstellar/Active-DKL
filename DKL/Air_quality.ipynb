{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Udem/DKL"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LSz1Wmkytb0","executionInfo":{"status":"ok","timestamp":1688797938057,"user_tz":240,"elapsed":854,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}},"outputId":"0832a8a3-a761-4c16-9205-def53850e168"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Udem/DKL\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTt0ILICb9cY","executionInfo":{"status":"ok","timestamp":1688797940290,"user_tz":240,"elapsed":259,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}},"outputId":"60050b5e-f728-4052-8deb-6ca5ce6d25ef"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Udem/DKL\n"]}]},{"cell_type":"code","source":["!pip install gpytorch\n","!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFpw8sgNyuv7","executionInfo":{"status":"ok","timestamp":1688779484304,"user_tz":240,"elapsed":17927,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}},"outputId":"fdd68477-5235-4725-e5e9-c2a276937e70"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gpytorch in /usr/local/lib/python3.10/dist-packages (1.11)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch) (1.2.2)\n","Requirement already satisfied: linear-operator>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from gpytorch) (0.5.0)\n","Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (2.0.1+cu118)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (1.10.1)\n","Requirement already satisfied: jaxtyping>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (0.2.20)\n","Requirement already satisfied: typeguard~=2.13.3 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (2.13.3)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.22.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.9->linear-operator>=0.5.0->gpytorch) (4.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->linear-operator>=0.5.0->gpytorch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.3.0)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.2.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.11.1)\n","Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from optuna) (0.9.1)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.16)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.6.3)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"cC6jQjD0gGCG","tags":[],"executionInfo":{"status":"ok","timestamp":1688779490296,"user_tz":240,"elapsed":5996,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import torch\n","import torch.optim as optim\n","from features import feature_prep_air_quality, inverse_transform, format_predictions, calculate_metrics\n","# from features import SequenceEncoder\n","from model import LSTMModel, ExactGPLayer,DeepGP, MLPModel, Bias, GPModel, WaveNet, ConvRNN\n","from run_exp import Optimization\n","\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import gpytorch\n","from gpytorch.mlls import VariationalELBO, AddedLossTerm\n","from gpytorch.mlls import DeepApproximateMLL\n","import time\n","import optuna\n","import pickle\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.ensemble import RandomForestRegressor\n","# from mapie.metrics import (regression_coverage_score, regression_mean_width_score)\n","# from mapie.regression import MapieRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n","from scipy.stats import randint\n","from sklearn.metrics import mean_absolute_error\n","import random\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["torch.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"_7CBs-QATo7G","executionInfo":{"status":"ok","timestamp":1688779490296,"user_tz":240,"elapsed":16,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}},"outputId":"e88edd2d-039d-478d-b32b-697bf69fa087"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.1+cu118'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["!python -V"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zADZlJgtZG4K","executionInfo":{"status":"ok","timestamp":1688779490296,"user_tz":240,"elapsed":11,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}},"outputId":"78d24c98-4200-4289-bff8-9a7f07ea3df7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"CGS0tZ1kyskX","executionInfo":{"status":"ok","timestamp":1688779491163,"user_tz":240,"elapsed":875,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}},"outputId":"50b22d80-c1aa-4ac2-fdcc-381ebce7d256"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Jul  8 01:24:49 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"cFAm8ulggsJb","tags":[],"executionInfo":{"status":"ok","timestamp":1688779492149,"user_tz":240,"elapsed":987,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}}},"outputs":[],"source":["# df = pd.read_csv('data.csv')\n","df = pd.read_excel('AirQualityUCI.xlsx')\n","df['hour'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.hour\n","df['month'] = pd.DatetimeIndex(df['Date']).month"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"vGtgS2OVm1fT","tags":[],"executionInfo":{"status":"ok","timestamp":1688782754551,"user_tz":240,"elapsed":318,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}}},"outputs":[],"source":["\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","def get_model(model, model_params):\n","    models = {\n","        \"convrnn\": ConvRNN,\n","        \"wavenet\": WaveNet,\n","        \"lstm\": LSTMModel,\n","        \"mlp\": MLPModel,\n","        \"bias\": Bias\n","    }\n","    return models.get(model.lower())(**model_params)\n","\n","def initialize_weights(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.kaiming_uniform_(m.weight.data).to(device)\n","        nn.init.constant_(m.bias.data, 0).to(device)\n","\n","def get_model_likelihood_mll(train_x=None, train_y=None, batch_size=64, input_dim=32, device=torch.device(\"cpu\"), mode = 'ExactGP', kernel='RBF'):\n","    # noise_prior = gpytorch.priors.Prior()\n","    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n","    if (train_x is None): train_x = torch.ones(batch_size, input_dim).to(device)\n","    if (train_y is None): train_y = torch.ones(batch_size).to(device)\n","    model = ExactGPLayer(train_x,train_y,likelihood, kernel=kernel)\n","    return model, likelihood\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"tags":[],"id":"Gp4oNOReyskX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688782758276,"user_tz":240,"elapsed":1267,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}},"outputId":"d4e2e590-2fd2-4e73-d2dd-bee8aa0c937a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f123fc87950>"]},"metadata":{},"execution_count":16}],"source":["#!unset LD_LIBRARY_PATH\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n"]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRvYvx2gFznJ","executionInfo":{"status":"ok","timestamp":1688783638465,"user_tz":240,"elapsed":520,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}},"outputId":"6d2bcb96-bad7-4e4d-b096-dad9dfb68804"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5393, 14)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","execution_count":18,"metadata":{"id":"pNFfOFDAnbex","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"77781831-9aed-493a-d202-cea4f995daa6","executionInfo":{"status":"ok","timestamp":1688782872639,"user_tz":240,"elapsed":113565,"user":{"displayName":"Hena Ghonia","userId":"03246241722682988409"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Identified outliers: 368\n","Non-outlier observations: 8989\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 256])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["[1/200] Training loss:  0.9649 - noise =  6.748170e-01 \t train_mse:  1.0075\n","[2/200] Training loss:  0.8057 - noise =  6.544352e-01 \t train_mse:  1.0046\n","[3/200] Training loss:  0.7657 - noise =  6.341863e-01 \t train_mse:  1.0027\n","[4/200] Training loss:  0.7426 - noise =  6.147937e-01 \t train_mse:  1.0016\n","[5/200] Training loss:  0.7245 - noise =  5.960623e-01 \t train_mse:  1.0017\n","[6/200] Training loss:  0.7084 - noise =  5.780129e-01 \t train_mse:  1.0021\n","[7/200] Training loss:  0.6983 - noise =  5.606295e-01 \t train_mse:  1.0026\n","[8/200] Training loss:  0.6800 - noise =  5.436474e-01 \t train_mse:  1.0031\n","[9/200] Training loss:  0.6616 - noise =  5.270418e-01 \t train_mse:  1.0039\n","[10/200] Training loss:  0.6482 - noise =  5.108765e-01 \t train_mse:  1.0042\n","[20/200] Training loss:  0.4764 - noise =  3.684361e-01 \t train_mse:  1.0119\n","[30/200] Training loss:  0.3103 - noise =  2.605737e-01 \t train_mse:  1.0219\n","[40/200] Training loss:  0.1474 - noise =  1.824932e-01 \t train_mse:  1.0243\n","[50/200] Training loss: -0.0431 - noise =  1.259417e-01 \t train_mse:  1.0308\n","[60/200] Training loss: -0.2026 - noise =  8.720611e-02 \t train_mse:  1.0333\n","[70/200] Training loss: -0.3897 - noise =  6.040000e-02 \t train_mse:  1.0319\n","[80/200] Training loss: -0.5139 - noise =  4.196555e-02 \t train_mse:  1.0347\n","[90/200] Training loss: -0.6804 - noise =  2.952136e-02 \t train_mse:  1.0378\n","[100/200] Training loss: -0.8684 - noise =  2.091006e-02 \t train_mse:  1.0398\n","[110/200] Training loss: -0.9399 - noise =  1.486110e-02 \t train_mse:  1.0453\n","[120/200] Training loss: -1.0958 - noise =  1.141417e-02 \t train_mse:  1.0429\n","[130/200] Training loss: -1.2133 - noise =  8.248466e-03 \t train_mse:  1.0436\n","[140/200] Training loss: -1.2135 - noise =  6.455511e-03 \t train_mse:  1.0397\n","[150/200] Training loss: -1.3239 - noise =  5.223456e-03 \t train_mse:  1.0349\n","[160/200] Training loss: -1.3873 - noise =  4.481398e-03 \t train_mse:  1.0319\n","[170/200] Training loss: -1.4646 - noise =  3.754194e-03 \t train_mse:  1.0310\n","[180/200] Training loss: -1.4152 - noise =  3.289562e-03 \t train_mse:  1.0287\n","[190/200] Training loss: -1.4998 - noise =  2.915132e-03 \t train_mse:  1.0288\n","[200/200] Training loss: -1.6000 - noise =  2.413804e-03 \t train_mse:  1.0295\n","Wall clock(in hours): 0.027490102648735047\n","Overall time taken(in hours): 0.03155592534277174\n","metrics {'mae': 5.0222, 'mse': 5.667732512521749, 'r2': 0.10969284797840362}\n"]}],"source":["start_time = time.time()\n","\n","batch_size = 256\n","X_train, y_train, train_features, train_targets, X_test,y_test, scaler, scaler1, train_loader,val_loader, test_loader, train_loader_one, test_loader_one = feature_prep_air_quality(df, batch_size=batch_size)\n","\n","device = torch.device(\"cpu\")\n","input_dim = X_train.shape[1]\n","output_dim = 1\n","hidden_dim = 100\n","layer_dim = 3\n","kernel = 1\n","out_channels = 24\n","\n","dropout = 0.2\n","n_epochs = 200\n","learning_rate = 0.001\n","weight_decay = 1e-6\n","\n","model_params = {'input_dim': input_dim,\n","                'hidden_dim': hidden_dim,\n","                'layer_dim': layer_dim,\n","                'output_dim': output_dim,\n","                'dropout_prob': dropout,\n","                'device': device}\n","\n","mlp_params = {'input_dim': input_dim, 'hidden_dim': hidden_dim, 'output_dim': output_dim}\n","bias_params = {'input_dim': output_dim, 'output_dim': output_dim, 'device': device}\n","convrnn_params = {'input_dim':input_dim, 'timesteps':X_train.shape[1], 'output_dim':output_dim, 'kernel_size1':7, 'kernel_size2':5, 'kernel_size3':3,\n","              'n_channels1':32, 'n_channels2':32, 'n_channels3':32, 'n_units1':32, 'n_units2':32, 'n_units3':32}\n","mode = 'LSTM_ExactGP'\n","#options:{LSTM_ExactGP, DeepGP, ExactGP, mlp_ExactGP}\n","\n","if mode == 'LSTM_ExactGP': # LSTM_ExactGP\n","    feature_extractor = get_model('lstm', model_params)\n","    feature_extractor.to(device)\n","    model, likelihood = get_model_likelihood_mll(train_x=None, train_y=None, batch_size=batch_size,\n","                                                  input_dim=output_dim, device=device, mode=mode)\n","    loss_fn = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n","    feature_extractor.apply(initialize_weights)\n","    model.to(device)\n","else:\n","\n","    feature_extractor = get_model('mlp', mlp_params)\n","    feature_extractor.to(device)\n","\n","    model, likelihood = get_model_likelihood_mll(train_x=None, train_y=None, batch_size=batch_size,input_dim=output_dim, device=device, mode=mode)\n","    model.to(device)\n","    likelihood.to(device)\n","    loss_fn = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n","    feature_extractor.apply(initialize_weights)\n","\n","\n","likelihood.to(device)\n","lr = 0.00177040768495762\n","\n","optimizer = torch.optim.Adam([\n","    {'params': feature_extractor.parameters(), 'lr': lr},\n","    {'params': model.covar_module.parameters(), 'lr': lr * 0.1},\n","    {'params': model.mean_module.parameters(), 'lr': lr},\n","    {'params': likelihood.parameters(), 'lr': lr}, ])\n","\n","opt = Optimization(feature_extractor=feature_extractor, model=model, likelihood=likelihood, loss_fn=loss_fn, optimizer=optimizer, device=device, mode=mode)\n","opt.train(train_loader,val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\n","opt.plot_losses()\n","\n","predictions, values,variance, lower_pred, upper_pred, mean_f, lower_f, upper_f= opt.evaluate(train_loader,test_loader_one, batch_size=1, n_features=input_dim)\n","\n","df_result = format_predictions(predictions,values,variance, lower_pred, upper_pred, mean_f, lower_f, upper_f, scaler1)\n","df_result.to_csv('results.csv', index=True)\n","\n","plt.figure(figsize=(20, 4))\n","plt.plot(df_result.tail(200)['prediction'], label=\"predicted\")\n","plt.plot(\n","    df_result.tail(200)['actual'], label=\"actual\"\n",")\n","\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Target values\")\n","plt.legend()\n","plt.savefig(\"Predictions.png\")\n","plt.close()\n","plt.figure(figsize=(20, 4))\n","plt.plot(\n","    df_result.head(200)['prediction'], label=\"predicted\"\n",")\n","\n","plt.plot(\n","    df_result.head(200)['actual'], label=\"actual\"\n",")\n","\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Target values\")\n","plt.legend()\n","plt.savefig(\"Predictions1.png\")\n","plt.close()\n","\n","print('Overall time taken(in hours):',(time.time()-start_time)/3600)\n","result_metrics = calculate_metrics(df_result)\n","print('metrics',result_metrics)\n","\n","plt.figure(figsize=(20, 6))\n","plt.plot(df_result.index, df_result['prediction'], 'b')\n","plt.fill_between(df_result.index, df_result['lower_pred'], df_result['upper_pred'], alpha=0.5)\n","plt.legend(['Mean', '95% Confidence'], fontsize=16)\n","plt.tick_params(axis='both', which='major', labelsize=16)\n","plt.tick_params(axis='both', which='minor', labelsize=16)\n","plt.tight_layout()\n","plt.savefig(\"Predictions2.png\")\n","plt.close()\n"]},{"cell_type":"code","source":["metrics {'mae': 3.9410331, 'mse': 4.550951830896332, 'r2': 0.4259817749709902} - epoch 50 spectral"],"metadata":{"id":"Z_avOuPbfl7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def objective(trial):\n","\n","    params = {\n","              'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n","              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n","              'batch_size': trial.suggest_categorical(\"batch\", [64, 128, 256]),\n","              'dropout':trial.suggest_loguniform('dropout', 0.1, 0.4),\n","              'kernel':trial.suggest_categorical(\"kernel\", ['RBF', 'spectral', 'cosine', 'matern', 'BNCosSim']),\n","              }\n","    features = ['draft_aft_telegram', 'draft_fore_telegram', 'stw',\n","    'diff_speed_overground', 'awind_vcomp_provider', 'awind_ucomp_provider',\n","    'rcurrent_vcomp', 'rcurrent_ucomp', 'comb_wind_swell_wave_height',\n","    'timeSinceDryDock']\n","    X_train = train[features]\n","    y_train = train['power']\n","    X_test = test[features]\n","    y_test = test['power']\n","\n","    X_train, y_train, train_features, train_targets, X_test,y_test, scaler, scaler1, train_loader,val_loader, test_loader, train_loader_one, test_loader_one = feature_prep(train, val, test, batch_size=params[\"batch_size\"])\n","    device = torch.device(\"cuda\")\n","    input_dim = X_train.shape[1]\n","    output_dim = 1\n","    hidden_dim = 100\n","    layer_dim = 3\n","    kernel = 1\n","    out_channels = 24\n","    mode = 'LSTM_ExactGP'\n","    dropout = params['dropout']\n","    n_epochs = 1\n","    learning_rate = 0.001\n","    weight_decay = 1e-6\n","\n","    model_params = {'input_dim': input_dim,\n","                    'hidden_dim': hidden_dim,\n","                    'layer_dim': layer_dim,\n","                    'output_dim': output_dim,\n","                    'dropout_prob': dropout,\n","                    'device': device}\n","    feature_extractor = get_model('lstm', model_params)\n","    feature_extractor.to(device)\n","    model, likelihood = get_model_likelihood_mll(train_x=None, train_y=None, batch_size=params[\"batch_size\"],\n","                                                  input_dim=output_dim, device=device, mode=mode, kernel = params[\"kernel\"])\n","    loss_fn = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n","    feature_extractor.apply(initialize_weights)\n","    model.to(device)\n","    # optim_params = list(feature_extractor.parameters()) + list(model.covar_module.parameters()) + list(model.mean_module.parameters()) + list(likelihood.parameters())\n","    # learn_params = list(lr) + list(lr*0.1) + list(lr) + list(lr)\n","    # optimizer = getattr(torch.optim, params['optimizer'])([feature_extractor.parameters(), lr= params['learning_rate']])\n","\n","    optimizer = getattr(torch.optim, params['optimizer'])([\n","    {'params': feature_extractor.parameters(), 'lr': params['learning_rate']},\n","    {'params': model.covar_module.parameters(), 'lr': params['learning_rate'] * 0.1},\n","    {'params': model.mean_module.parameters(), 'lr': params['learning_rate']},\n","    {'params': likelihood.parameters(), 'lr': params['learning_rate']}, ])\n","\n","    opt = Optimization(feature_extractor=feature_extractor, model=model, likelihood=likelihood, loss_fn=loss_fn, optimizer=optimizer, device=device, mode=mode)\n","    opt.train(train_loader,val_loader, batch_size=params[\"batch_size\"], n_epochs=n_epochs, n_features=input_dim)\n","    predictions, values,variance, lower_pred, upper_pred, mean_f, lower_f, upper_f = opt.evaluate(train_loader, test_loader_one, batch_size=1, n_features=input_dim)\n","    df_result = format_predictions(predictions,values,variance, lower_pred, upper_pred, mean_f, lower_f, upper_f, scaler1)\n","    # print('values',np.concatenate(values, axis=0).ravel().shape)\n","    # print('prediction',np.concatenate(predictions, axis=0).ravel().shape)\n","    # mae_mean = mean_absolute_error(np.concatenate(values, axis=0).ravel(), np.concatenate(predictions, axis=0).ravel())\n","    result_metrics = calculate_metrics(df_result)\n","    return result_metrics[\"mae\"]\n"],"metadata":{"id":"muZ4Z32k_Pb8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=10)\n","print('Number of finished trials:', len(study.trials))\n","print('Best trial:', study.best_trial.params)"],"metadata":{"id":"blh50BseAYm2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUSWFnQHoOoa","tags":[]},"outputs":[],"source":["# 1epoch: 'mae': 1260.5171, 'mse': 1578.8270171237887, 'r2': 0.9137536772367476 batch active learning\n","#100 epochs: 'mae': 5453.195, 'mse': 6785.376923944608, 'r2': 0.2265047417595234\n","#200 epochs metrics {'mae': 4877.8594, 'mse': 6272.694158015358, 'r2': 0.3389748865544878}\n","#100 epochs with transformer encoder metrics {'mae': 6439.92, 'mse': 7715.523313424696, 'r2': -9.323326833987622e-05}\n","#Area under Mean Square error (MSE) and F1 retention curves [Malinin, 2019, Malinin et al., 2021] is used to assess jointly the robustness to distributional shift and uncertainty quality."]},{"cell_type":"code","source":[],"metadata":{"id":"v0Opxq4H_Op9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7SvmDLFcv4l-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yWA1he9ryskZ"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}